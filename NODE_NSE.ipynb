{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21725,"status":"ok","timestamp":1689720870455,"user":{"displayName":"Luke McLennan","userId":"05318381855726906118"},"user_tz":300},"id":"1FXYOspA13S2","outputId":"544e6038-2621-4d00-e1a9-dba7bb809c63"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torchdiffeq\n","  Downloading torchdiffeq-0.2.3-py3-none-any.whl (31 kB)\n","Requirement already satisfied: torch\u003e=1.3.0 in /usr/local/lib/python3.10/dist-packages (from torchdiffeq) (2.0.1+cu118)\n","Requirement already satisfied: scipy\u003e=1.4.0 in /usr/local/lib/python3.10/dist-packages (from torchdiffeq) (1.10.1)\n","Requirement already satisfied: numpy\u003c1.27.0,\u003e=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy\u003e=1.4.0-\u003etorchdiffeq) (1.22.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.3.0-\u003etorchdiffeq) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.3.0-\u003etorchdiffeq) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.3.0-\u003etorchdiffeq) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.3.0-\u003etorchdiffeq) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.3.0-\u003etorchdiffeq) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.3.0-\u003etorchdiffeq) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch\u003e=1.3.0-\u003etorchdiffeq) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch\u003e=1.3.0-\u003etorchdiffeq) (16.0.6)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch\u003e=1.3.0-\u003etorchdiffeq) (2.1.3)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch\u003e=1.3.0-\u003etorchdiffeq) (1.3.0)\n","Installing collected packages: torchdiffeq\n","Successfully installed torchdiffeq-0.2.3\n"]}],"source":["import torch\n","from torch import nn\n","from torch import optim\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","from sklearn.gaussian_process import GaussianProcessRegressor as GPR\n","from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n","!pip install torchdiffeq\n","from torchdiffeq import odeint_adjoint, odeint\n","import numpy as np\n","from scipy import io\n","import argparse\n","import os\n","import pickle\n","import matplotlib.pyplot as plt\n","import zipfile\n","from timeit import default_timer\n","from google.colab import drive\n","import h5py"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33486,"status":"ok","timestamp":1689720903936,"user":{"displayName":"Luke McLennan","userId":"05318381855726906118"},"user_tz":300},"id":"UzpzPDVmdaew","outputId":"55eaad6c-0168-454c-a7e4-9d615715c10a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["drive.mount('/content/drive')\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","directory = \"drive/MyDrive/Fourier Neural Operator/data/\"#\"spring-runs_train/\" #/mnt/data/datasets/physical_system_benchmark/experiment_output/spring/spring/run/data_gen/spring-runs_train-spring-n1000-t805-n0_00001/\"\n","zip = zipfile.ZipFile(directory + \"NavierStokes_V1e-5_N1200_T20.zip\")\n","zip.extractall()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":950,"status":"ok","timestamp":1689720904861,"user":{"displayName":"Luke McLennan","userId":"05318381855726906118"},"user_tz":300},"id":"-KRhzsU-Zwxf","outputId":"f484bc24-96c1-491e-b3ac-73d2e95e3e68"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1200, 64, 64, 20]) torch.Size([1200, 64, 64])\n"]}],"source":["npz = io.loadmat(\"NavierStokes_V1e-5_N1200_T20.mat\")\n","# npz = h5py.File(\"NavierStokes_V1e-5_N1200_T20.mat\")\n","u = torch.tensor(npz[\"u\"], device=device, dtype=torch.float32)\n","a = torch.tensor(npz[\"a\"], device=device, dtype=torch.float32)\n","print(u.shape, a.shape)\n","nb_trajs = 1200\n","x_width = 64\n","y_width = 64\n","# initial = torch.tensor(a, dtype = torch.float32)\n","# final = torch.tensor(x, dtype = torch.float32)\n","# p_exact = torch.tensor(p1, dtype = torch.float32)\n","# t = torch.linspace(0,1,nb_times, dtype = torch.float32)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1689720904863,"user":{"displayName":"Luke McLennan","userId":"05318381855726906118"},"user_tz":300},"id":"2mQJSSkq2Hal"},"outputs":[],"source":["# directory = \"drive/MyDrive/Fourier Neural Operator/data\"#\"spring-runs_train/\" #/mnt/data/datasets/physical_system_benchmark/experiment_output/spring/spring/run/data_gen/spring-runs_train-spring-n1000-t805-n0_00001/\"\n","# npz = np.load(directory + \"burgers_data_R10.mat\")\n","# nb_trajs = 50\n","# start_traj = 0\n","# nb_times = 10205\n","# x_width = 125\n","# p1, q1, dqdt1, dpdt1, t1 = np.zeros((nb_trajs,x_width,nb_times)), np.zeros((nb_trajs,x_width,nb_times)), np.zeros((nb_trajs,x_width,nb_times)), np.zeros((nb_trajs,x_width,nb_times)), np.zeros((nb_trajs,x_width,nb_times))\n","# for i in range(start_traj, start_traj + nb_trajs):\n","#   p1[i,:,:], q1[i,:,:], dqdt1[i,:,:], dpdt1[i,:,:], t1[i,:,:] = npz[npz.files[5*i+0]].T, npz[npz.files[5*i+1]].T, npz[npz.files[5*i+2]].T, npz[npz.files[5*i+3]].T, npz[npz.files[5*i+4]].T\n","# q_exact = torch.tensor(q1, dtype = torch.float32)\n","# p_exact = torch.tensor(p1, dtype = torch.float32)\n","# t = torch.tensor(t1[0], dtype = torch.float32)\n","# exact = torch.cat((q_exact.reshape(nb_trajs,x_width,nb_times,1), p_exact.reshape(nb_trajs,x_width,nb_times,1)), dim=-1)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1689720904863,"user":{"displayName":"Luke McLennan","userId":"05318381855726906118"},"user_tz":300},"id":"zPSNy7oqItdz"},"outputs":[],"source":["test_trajs = 200\n","data = u #torch.cat((a.reshape(nb_trajs,x_width,1), u.reshape(nb_trajs,x_width,1)), dim=-1)\n","train_loader = DataLoader(data[:(nb_trajs-test_trajs)], batch_size=16)\n","test_loader  = DataLoader(data[(nb_trajs-test_trajs):], batch_size=16)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1689720904864,"user":{"displayName":"Luke McLennan","userId":"05318381855726906118"},"user_tz":300},"id":"2fELOSgY6ncA","outputId":"0b6736ce-5689-4557-cf07-ac8cfd293c9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1200, 64, 64, 20])\n","1200 200\n","torch.Size([200, 64, 64, 20])\n"]}],"source":["print(u.shape)\n","print(nb_trajs, test_trajs)\n","print(u[(nb_trajs-test_trajs):].shape)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1689720904864,"user":{"displayName":"Luke McLennan","userId":"05318381855726906118"},"user_tz":300},"id":"Mj5tWMTN2Llx"},"outputs":[],"source":["class Lyapunov(nn.Module):\n","  def __init__(self, in_nodes, layers, activation):\n","    super(Lyapunov, self).__init__()\n","    self.in_nodes = in_nodes\n","    self.layers = layers\n","    self.act = activation\n","    self.w0 = nn.Linear(in_nodes, in_nodes)\n","    self.w1 = nn.Linear(in_nodes, 1)\n","    self.u1 = nn.Parameter(torch.Tensor(1, in_nodes))\n","    nn.init.xavier_uniform_(self.u1)\n","    self.g0 = self.g(torch.zeros(in_nodes))\n","  def g(self, x):\n","    z = self.act(self.w0(x))\n","    z = self.act(self.w1(x)  + F.linear(z, self.u1.exp()))\n","    return z\n","  def forward(self, x):\n","    return self.act(self.g(x) - self.g0) + torch.sum(x**2, dim=1).reshape(-1,1)/100\n","# class Lyapunov(nn.Module):\n","#   def __init__(self, in_nodes, layers, activation):\n","#     super(Lyapunov, self).__init__()\n","#     self.in_nodes = in_nodes\n","#     self.layers = layers\n","#     self.act = activation\n","#     self.W = [nn.Linear(in_nodes, in_nodes)]\n","#     self.U = []\n","#     for i in range(layers):\n","#       self.W.append(nn.Linear(in_nodes, in_nodes))\n","#       self.U.append(nn.Linear(in_nodes, in_nodes))\n","#     self.W.append(nn.Linear(in_nodes, 1))\n","#     self.U.append(nn.Linear(in_nodes, 1))\n","#     self.g0 = self.g(torch.zeros(in_nodes))\n","#   def g(self, x):\n","#     z = self.act(self.W[0](x))\n","#     for i in range(self.layers):\n","#       z = self.act(self.W[i+1](x) + self.U[i](z)**2)\n","#     z = self.act(self.W[self.layers+1](x) + self.U[self.layers](z)**2)\n","#     return z\n","#   def forward(self, x):\n","#     return self.act(self.g(x) - self.g0) + torch.norm(x, p=2)/100"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1689720904865,"user":{"displayName":"Luke McLennan","userId":"05318381855726906118"},"user_tz":300},"id":"xpRguIif2RBg"},"outputs":[],"source":["class ODEFunc(nn.Module):\n","    def __init__(self, in_nodes, hid_nodes, v_layers, v_act):\n","        super(ODEFunc, self).__init__()\n","        self.fc0 = nn.Linear(in_nodes+1, hid_nodes)\n","        self.fc1 = nn.Linear(hid_nodes, in_nodes)\n","        self.V = Lyapunov(in_nodes, v_layers, v_act)\n","    def forward(self, t, x):\n","        x = x.requires_grad_(True)\n","        tt = torch.ones_like(x[...,:1], requires_grad=True)*t\n","        xt = torch.cat((tt, x), dim=-1)\n","        fx = self.fc0(xt)\n","        fx = F.gelu(fx)\n","        fx = self.fc1(fx)\n","        # Vx = self.V(x)\n","        # grad_Vx = torch.autograd.grad(Vx, x, torch.ones(Vx.shape), create_graph=True, allow_unused=True, retain_graph=True)[0]\n","        # alpha = 1\n","        # fx = fx - grad_Vx*torch.relu(torch.sum(grad_Vx*fx,dim=1).reshape(-1,1) + alpha*Vx)/torch.sum(grad_Vx**2, dim=1).reshape(-1,1)\n","        return fx"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":271,"status":"ok","timestamp":1689720905125,"user":{"displayName":"Luke McLennan","userId":"05318381855726906118"},"user_tz":300},"id":"cSz7AWZK2_XU"},"outputs":[],"source":["class NODE(nn.Module):\n","    def __init__(self, in_nodes, hid_nodes, tol, v_layers, v_act):\n","        super(NODE, self).__init__()\n","        self.ode = ODEFunc(in_nodes, hid_nodes, v_layers, v_act)\n","        self.fc0 = nn.Linear(2, in_nodes)\n","        self.fc1 = nn.Linear(in_nodes, 2)\n","        self.tol = tol\n","    def forward(self, x):\n","        x = x.requires_grad_(True)\n","        x = x.reshape(x.shape[0], -1)\n","        x = self.fc0(x)\n","        x0 = x\n","        x = odeint(self.ode, x, torch.tensor([0., 1.], device=x.device), atol=self.tol, rtol=self.tol)[-1]\n","        x = self.fc1(x)\n","        return x"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1689720905126,"user":{"displayName":"Luke McLennan","userId":"05318381855726906118"},"user_tz":300},"id":"yZarwrnG3BwW","outputId":"d36ee0a0-1a0a-42c6-953f-2c845c863e0b"},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]}],"source":["skip_size = 1\n","nb_times = u.shape[-1]//skip_size\n","skip_size_2 = 2\n","Nt = nb_times//skip_size\n","Nx = (x_width//skip_size_2)*(y_width//skip_size_2)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","# model = NODE(32, 128, 1e-5, 3, nn.Softplus()).to(device)\n","latent_channels = 64\n","hidden_layers = 128\n","odefunc = ODEFunc(latent_channels, hidden_layers, 2, nn.ReLU())\n","prelayer = nn.Linear(Nx, latent_channels)\n","postlayer = nn.Linear(latent_channels, Nx)\n","params = list(odefunc.parameters()) + list(prelayer.parameters()) + list(postlayer.parameters())\n","optim = torch.optim.Adam(params, lr=1e-3)\n","loss_fn = nn.MSELoss()\n","tol = 1e-5\n","mse_train_losses = []\n","mse_test_losses = []\n","lyap_train_losses = []\n","lyap_test_losses = []\n","accuracies = []"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1689720905126,"user":{"displayName":"Luke McLennan","userId":"05318381855726906118"},"user_tz":300},"id":"yeAig_Mfp46z"},"outputs":[],"source":["epochs = 500"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"QwyZAkWX3F1u"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 58.064825641 0.9651555882559882 132.08886542687048 0.9651555882559882 1.8686963594876802\n","10 48.665431890000036 0.6317740640943013 134.78252880389874 0.6317740640943013 1.8822081272418683\n","20 54.615793077000035 0.6279995479280986 135.7416446392353 0.6279995479280986 1.8951440774477446\n","30 53.630765870999994 0.6263979626080346 136.41779327392578 0.6263979626080346 1.9044406505731435\n","40 49.83357465600011 3.640031996227446 374.9520791860727 3.640031996227446 5.3114705085754395\n","50 49.87935647600034 3.607192101932707 371.31331810584436 3.607192101932707 5.259929436903733\n","60 52.393155373000354 3.5669033262464733 366.8315194936899 3.5669033262464733 5.196400000498845\n","70 49.336546602 3.5191505522955033 361.5105813833383 3.5191505522955033 5.120907178291907\n","80 49.810406209000575 3.4642104705174765 355.41156710111176 3.4642104705174765 5.034278942988469\n","90 48.79366077400027 3.4025795497591536 348.65211017315204 3.4025795497591536 4.938144537118765\n","100 49.12293819500064 3.334982323268103 341.4021653395433 3.334982323268103 4.834869458125188\n"]}],"source":["alpha = 5\n","grads = []\n","grads_added = False\n","filter = []\n","for i in range(epochs):\n","    t = default_timer()\n","    lyap_train_loss = 0\n","    mse_train_loss = 0\n","    mse_test_loss = 0\n","    lyap_test_loss = 0\n","    for x in train_loader:\n","        x = x[:,::skip_size_2,::skip_size_2]\n","        x0 = x[:,:,:,0].to(device).requires_grad_(True)\n","        x0 = x0.reshape(x.shape[0], -1)\n","        z0 = prelayer(x0)\n","        zt = odeint_adjoint(odefunc, z0, torch.linspace(0,1,Nt), atol=tol, rtol=tol)\n","        pred = postlayer(zt)\n","        pred = pred.permute(2, 0, 1)\n","        pred = pred.reshape(x.shape)\n","        # print(pred.shape, x.shape)\n","        # loss = loss_fn(pred,x[:,::skip_size,:])\n","        loss = torch.tensor(0.0, requires_grad=True, device=device)\n","        # print(pred.shape, x.shape)\n","        loss = loss_fn(pred, x)\n","        # loss_now = loss_fn(pred[0], x0[0])\n","        # for j in range(1,pred.shape[0]):\n","        #   loss_prev = loss_now\n","        #   loss_now = loss_fn(pred[j], x0[j])\n","        #   loss = loss + torch.relu(loss_now + (alpha-1)*loss_prev)\n","        optim.zero_grad()\n","        loss.backward()\n","        for k,p in enumerate(params):\n","          if not grads_added:\n","            grads.append(torch.abs(p.grad))\n","            filter.append(torch.ones(p.grad.shape))\n","          else:\n","            grads[k] = grads[k] + torch.abs(p.grad)\n","        grads_added = True\n","        for j, p in enumerate(params):\n","          p.grad = p.grad*filter[j]\n","        optim.step()\n","        lyap_train_loss += loss.item()\n","        mse_train_loss += loss_fn(pred, x).item()\n","    for x in test_loader:\n","        x = x[:,::skip_size_2,::skip_size_2]\n","        x0 = x[:,:,:,0].to(device).requires_grad_(True)\n","        x0 = x0.reshape(x.shape[0], -1)\n","        z0 = prelayer(x0)\n","        zt = odeint(odefunc, z0, torch.linspace(0,1,Nt), atol=tol, rtol=tol)\n","        pred = postlayer(zt)\n","        pred = pred.reshape(x.shape)\n","        # pred = pred.permute(2, 0, 1, 3)\n","        loss = torch.tensor(0.0, requires_grad=True, device=device)\n","        loss_now = loss_fn(pred[0], x[0])\n","        for j in range(1,pred.shape[0]):\n","          loss_prev = loss_now\n","          loss_now = loss_fn(pred[j], x[j])\n","          loss = loss + torch.relu(loss_now + (alpha-1)*loss_prev)\n","        lyap_test_loss += loss.item()\n","        mse_test_loss += loss_fn(pred, x).item()\n","    mse_train_loss /= len(train_loader)\n","    mse_test_loss /= len(test_loader)\n","    lyap_train_loss /= len(train_loader)\n","    lyap_test_loss /= len(test_loader)\n","    mse_train_losses.append(mse_train_loss)\n","    mse_test_losses.append(mse_test_loss)\n","    lyap_train_losses.append(lyap_train_loss)\n","    lyap_test_losses.append(lyap_test_loss)\n","    if i%10==0 or i ==epochs-1:\n","      print(i, default_timer()-t, lyap_train_loss, lyap_test_loss, mse_train_loss, mse_test_loss)\n","      # for p,g,f in zip(params,grads,filter):\n","      #   j = torch.argmax(f/g, keepdim=True)\n","      #   # print(j, g.flatten()[j])\n","      #   f2 = f.flatten()\n","      #   f2[j] = 0\n","      #   f = f2.reshape(f.shape)\n","        # print(p[j//p.shape[1],j%p.shape[1]])\n","        # p[j//p.shape[1],j%p.shape[1]].requires_grad = False\n","        # p.requires_grad=False\n","        # print(j)\n","        # print(p.shape, g.shape)\n","        # print(p.flatten()[j], g.flatten()[j])\n","# for g in grads:\n","#   print(g)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3BVJpLHUYRpn"},"outputs":[],"source":["torch.save([lyap_train_losses, lyap_test_losses, mse_train_losses, mse_test_losses], \"node_nse_losses.data\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9VBz73HD8AEH"},"outputs":[],"source":["torch.save([prelayer.state_dict(), odefunc.state_dict(), postlayer.state_dict()], \"node_nse_model.data\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NWMdV7LnZwxk"},"outputs":[],"source":["plt.plot(range(len(mse_train_losses)), np.array(mse_train_losses), label=\"MSE train loss\")\n","plt.plot(range(len(mse_test_losses)), np.array(mse_test_losses), label=\"MSE test loss\")\n","plt.yscale('log')\n","plt.legend()\n","plt.show()\n","plt.plot(range(len(lyap_train_losses)), np.array(lyap_train_losses), label=\"Lyap. train loss\")\n","plt.plot(range(len(lyap_test_losses)), np.array(lyap_test_losses), label=\"Lyap. test loss\")\n","plt.yscale('log')\n","plt.legend()\n","plt.show()\n","plt.plot(range(len(mse_test_losses)), np.abs(np.array(mse_test_losses)-np.array(mse_train_losses)), label=\"MSE difference\")\n","plt.yscale('log')\n","plt.legend()\n","plt.show()\n","plt.plot(range(len(lyap_test_losses)), np.abs(np.array(lyap_test_losses)-np.array(lyap_train_losses)), label=\"Lyap. difference\")\n","plt.legend()\n","plt.yscale('log')\n","plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN7c6Eptbu480MSVGFoW23l","name":"","provenance":[{"file_id":"1lZ9bGolY5CekwLaGkd2tMyZmO_xtb9Hm","timestamp":1689455518044},{"file_id":"155g7j5xMTMGkQJtciQ6zXHxvCAHEwAMj","timestamp":1688871897265},{"file_id":"1oEUVEX12S7CTukeUyzA_w8Y1UPuy824m","timestamp":1688761815902},{"file_id":"19btNNzNCoRkktc87sqJDWQ6LY47GETdo","timestamp":1688156252218},{"file_id":"1Y4UoIhAYn-IDWHjNdx6Zpj2LcOJXxxu3","timestamp":1687663152617},{"file_id":"1uoRiiJxJNvycS1YYSHBLvkfbEigQePTh","timestamp":1687295965944}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}